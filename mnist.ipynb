{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNhoF/GaSf64yVYHWVpUmdb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiviagarwal21/ml-devops/blob/master/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF8MCj2IRNur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ddee28e9-4cce-4ec5-d88a-d375201bb78f"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "\n",
        "# loads the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test)  = mnist.load_data()\n",
        "\n",
        "# Lets store the number of rows and columns\n",
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_train[1].shape[0]\n",
        "\n",
        "# Getting our date in the right 'shape' needed for Keras\n",
        "# We need to add a 4th dimenion to our date thereby changing our\n",
        "# Our original image shape of (60000,28,28) to (60000,28,28,1)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "# store the shape of a single image \n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# change our image type to float32 data type\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalize our data by changing the range from (0 to 255) to (0 to 1)\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Now we one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
        "accuracy=0\n",
        "conv=1\n",
        "cnt=0\n",
        "epochs=2\n",
        "while True:\n",
        "    cnt+=1\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    #sets of CRP (Convolution, RELU, Pooling)\n",
        "    for x in range(conv):\n",
        "        model.add(Conv2D(20, (5, 5),\n",
        "                        padding = \"same\", \n",
        "                        input_shape = input_shape))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
        "\n",
        "    # Fully connected layers (w/ RELU)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(500))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    # Softmax for classification\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "            \n",
        "    model.compile(loss = 'categorical_crossentropy',\n",
        "                optimizer = keras.optimizers.Adadelta(),\n",
        "                metrics = ['accuracy'])\n",
        "        \n",
        "    print(model.summary())\n",
        "\n",
        "    # Training Parameters\n",
        "    batch_size = 128\n",
        "\n",
        "    history = model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            shuffle=True)\n",
        "\n",
        "    model.save(\"mnist_LeNet.h5\")\n",
        "\n",
        "    # Evaluate the performance of our trained model\n",
        "    scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "    print('Test loss = ', scores[0])\n",
        "    print('Test accuracy = ', scores[1])\n",
        "    accuracy=scores[1]\n",
        "    print(accuracy)\n",
        "    if accuracy < 0.985 and cnt<2:\n",
        "        conv+=1\n",
        "        continue\n",
        "    elif accuracy < 0.985 :\n",
        "        epochs+=1\n",
        "    else:\n",
        "        break \n",
        "\n",
        "file = open(\"accuracy.txt\",\"w\")\n",
        "file.write(str(scores[1]*100))\n",
        "file.close()\n",
        "\n",
        "model.save(\"mnist_LeNet_correct.h5\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 20)        520       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 20)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 20)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3920)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               1960500   \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,966,030\n",
            "Trainable params: 1,966,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 50s 839us/step - loss: 0.2158 - accuracy: 0.9340 - val_loss: 0.0928 - val_accuracy: 0.9682\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 50s 828us/step - loss: 0.0591 - accuracy: 0.9824 - val_loss: 0.0646 - val_accuracy: 0.9777\n",
            "10000/10000 [==============================] - 3s 302us/step\n",
            "Test loss: 0.06457273348728194\n",
            "Test accuracy: 0.9776999950408936\n",
            "0.9776999950408936\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 20)        520       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 28, 28, 20)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 20)        10020     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 14, 14, 20)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 20)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 980)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 500)               490500    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5010      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 506,050\n",
            "Trainable params: 506,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 74s 1ms/step - loss: 0.2011 - accuracy: 0.9376 - val_loss: 0.0552 - val_accuracy: 0.9824\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.0519 - accuracy: 0.9838 - val_loss: 0.0358 - val_accuracy: 0.9876\n",
            "10000/10000 [==============================] - 4s 393us/step\n",
            "Test loss: 0.03578486169704702\n",
            "Test accuracy: 0.9876000285148621\n",
            "0.9876000285148621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb5rpIegSnZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}